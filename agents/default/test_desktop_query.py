#!/usr/bin/env python3
"""æµ‹è¯• Agent çš„æ¡Œé¢æŸ¥è¯¢åŠŸèƒ½"""

import asyncio
from src.agent.graph import graph
from src.agent.state import State
from langchain_core.messages import HumanMessage


async def test_desktop_query():
    """æµ‹è¯•æ¡Œé¢æŸ¥è¯¢åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯• Agent æ¡Œé¢å’Œæ–‡ä»¶æ“ä½œåŠŸèƒ½\n")
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        "æ¡Œé¢ä¸Šæœ‰å“ªäº›æ–‡ä»¶ï¼Ÿ",
        "æŸ¥çœ‹ DeepSeekåº”ç”¨æ‰‹å†Œ.docx æ–‡ä»¶çš„ä¿¡æ¯",
        "æœç´¢æ¡Œé¢ä¸Šæ˜¯å¦æœ‰åŒ…å« 'cli' å…³é”®è¯çš„æ–‡ä»¶æˆ–ç›®å½•",
        "ä½¿ç”¨ç½‘ç»œæœç´¢åŠŸèƒ½æœç´¢ 'MCP Model Context Protocol' çš„æœ€æ–°ä¿¡æ¯"
    ]
    
    for i, query in enumerate(test_cases, 1):
        print(f"ğŸ¤– æµ‹è¯•ç”¨ä¾‹ {i}: {query}")
        
        # åˆ›å»ºåˆå§‹çŠ¶æ€
        initial_state = State(
            messages=[HumanMessage(content=query)]
        )
        
        try:
            # è¿è¡Œ Agent
            result = await graph.ainvoke(initial_state)
            
            # è·å– Assistant çš„å›å¤
            if result.get("messages"):
                assistant_response = result["messages"][-1].content
                print(f"ğŸ¤– Assistant å›å¤:\n{assistant_response}\n")
                print("ğŸ“Š æµ‹è¯•ç»“æœ: âœ… æˆåŠŸ")
            else:
                print("âŒ æ²¡æœ‰æ”¶åˆ°å›å¤")
                print("ğŸ“Š æµ‹è¯•ç»“æœ: âŒ å¤±è´¥")
        
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            print("ğŸ“Š æµ‹è¯•ç»“æœ: âŒ å¤±è´¥")
        
        print("-" * 80)
        print()


if __name__ == "__main__":
    asyncio.run(test_desktop_query()) 